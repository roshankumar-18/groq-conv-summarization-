{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai groq --quiet\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n"
      ],
      "metadata": {
        "id": "dSj9FYUEdAYG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"]='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'"
      ],
      "metadata": {
        "id": "XVCXO2nidD5l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=os.environ[\"GROQ_API_KEY\"], base_url='https://api.groq.com/openai/v1')"
      ],
      "metadata": {
        "id": "PSh4wjECdbGw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationManager:\n",
        "    def __init__(self, model=\"llama-3.1-8b-instant\", k=3):\n",
        "        self.history = []  # stores dicts {\"role\": \"user/assistant/system\", \"content\": \"...\"}\n",
        "        self.summaries = []  # stores periodic summaries\n",
        "        self.model = model\n",
        "        self.k = k  # summarize every k turns\n",
        "        self.run_count = 0\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        \"\"\"Add a message to the conversation history\"\"\"\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "        self.run_count += 1\n",
        "\n",
        "        # Check if periodic summarization needed\n",
        "        if self.run_count % self.k == 0:\n",
        "            self.summarize_history()\n",
        "\n",
        "    def summarize_history(self):\n",
        "        \"\"\"Summarize conversation history and replace with summary\"\"\"\n",
        "        prompt = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes conversations concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize this conversation:\\n\\n{self.history}\"}\n",
        "        ]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=prompt,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        summary = response.choices[0].message.content.strip()\n",
        "        self.summaries.append(summary)\n",
        "\n",
        "        self.history = [{\"role\": \"system\", \"content\": f\"Summary so far: {summary}\"}]\n",
        "\n",
        "    def truncate_by_turns(self, n=5):\n",
        "        \"\"\"Keep only the last n messages\"\"\"\n",
        "        if len(self.history) > n:\n",
        "            self.history = self.history[-n:]\n",
        "\n",
        "    def truncate_by_length(self, max_chars=500):\n",
        "        \"\"\"Keep only up to max_chars of recent conversation\"\"\"\n",
        "        total = 0\n",
        "        truncated = []\n",
        "        for msg in reversed(self.history):\n",
        "            if total + len(msg[\"content\"]) <= max_chars:\n",
        "                truncated.insert(0, msg)\n",
        "                total += len(msg[\"content\"])\n",
        "            else:\n",
        "                break\n",
        "        self.history = truncated\n",
        "\n",
        "    def show_history(self):\n",
        "        return self.history\n",
        "\n",
        "    def show_summaries(self):\n",
        "        return self.summaries"
      ],
      "metadata": {
        "id": "lcTHR_FQdk1I"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_message(self, role, content):\n",
        "        \"\"\"Add a message to the conversation history\"\"\"\n",
        "        self.history.append({\"role\": role, \"content\": content})\n",
        "        self.run_count += 1\n",
        "\n",
        "        # Check if periodic summarization needed\n",
        "        if self.run_count % self.k == 0:\n",
        "            self.summarize_history()\n"
      ],
      "metadata": {
        "id": "1FXRhWc-dmAK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    def summarize_history(self):\n",
        "        \"\"\"Summarize conversation history and replace with summary\"\"\"\n",
        "        prompt = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes conversations concisely.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize this conversation:\\n\\n{self.history}\"}\n",
        "        ]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=prompt,\n",
        "            max_tokens=150\n",
        "        )\n",
        "\n",
        "        summary = response.choices[0].message.content.strip()\n",
        "        self.summaries.append(summary)\n",
        "\n",
        "        self.history = [{\"role\": \"system\", \"content\": f\"Summary so far: {summary}\"}]\n"
      ],
      "metadata": {
        "id": "Kiv9yZnydp5E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate_by_turns(self, n=5):\n",
        "        \"\"\"Keep only the last n messages\"\"\"\n",
        "        if len(self.history) > n:\n",
        "            self.history = self.history[-n:]\n",
        "\n",
        "def truncate_by_length(self, max_chars=500):\n",
        "        \"\"\"Keep only up to max_chars of recent conversation\"\"\"\n",
        "        total = 0\n",
        "        truncated = []\n",
        "        for msg in reversed(self.history):\n",
        "            if total + len(msg[\"content\"]) <= max_chars:\n",
        "                truncated.insert(0, msg)\n",
        "                total += len(msg[\"content\"])\n",
        "            else:\n",
        "                break\n",
        "        self.history = truncated\n",
        "\n",
        "def show_history(self):\n",
        "        return self.history\n",
        "\n",
        "def show_summaries(self):\n",
        "        return self.summaries"
      ],
      "metadata": {
        "id": "U6-fluKSd3mb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = ConversationManager(k=3)\n",
        "# Simulated conversation\n",
        "samples = [\n",
        "    (\"user\", \"Hi, I want to learn Python.\"),\n",
        "    (\"assistant\", \"Great! Python is beginner-friendly. Do you know about variables?\"),\n",
        "    (\"user\", \"Yes, I know a bit. What about loops?\"),\n",
        "    (\"assistant\", \"Loops allow repeating actions. For example, a for loop.\"),\n",
        "    (\"user\", \"Can you show me an example with numbers?\"),\n",
        "    (\"assistant\", \"Sure! for i in range(5): print(i) will print 0â€“4.\"),\n",
        "    (\"user\", \"Awesome, what about functions?\")\n",
        "]\n",
        "\n",
        "for role, msg in samples:\n",
        "    conv.add_message(role, msg)\n",
        "    print(f\"Added: {role}: {msg}\")\n",
        "    print(\"History now:\", conv.show_history())\n",
        "    print(\"Summaries:\", conv.show_summaries())\n",
        "    print(\"-\"*50)\n",
        "\n",
        "# -----------------------------\n",
        "# Truncation Examples\n",
        "# -----------------------------\n",
        "print(\"\\nðŸ”¹ Truncation by turns (last 3 messages):\")\n",
        "conv.truncate_by_turns(3)\n",
        "print(conv.show_history())\n",
        "\n",
        "print(\"\\nðŸ”¹ Truncation by length (max 100 chars):\")\n",
        "conv.truncate_by_length(100)\n",
        "print(conv.show_history())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vraQdbldeDxU",
        "outputId": "177bddda-e9d5-4e4a-da02-6bb795e43bab"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: user: Hi, I want to learn Python.\n",
            "History now: [{'role': 'user', 'content': 'Hi, I want to learn Python.'}]\n",
            "Summaries: []\n",
            "--------------------------------------------------\n",
            "Added: assistant: Great! Python is beginner-friendly. Do you know about variables?\n",
            "History now: [{'role': 'user', 'content': 'Hi, I want to learn Python.'}, {'role': 'assistant', 'content': 'Great! Python is beginner-friendly. Do you know about variables?'}]\n",
            "Summaries: []\n",
            "--------------------------------------------------\n",
            "Added: user: Yes, I know a bit. What about loops?\n",
            "History now: [{'role': 'system', 'content': 'Summary so far: This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.'}]\n",
            "Summaries: ['This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.']\n",
            "--------------------------------------------------\n",
            "Added: assistant: Loops allow repeating actions. For example, a for loop.\n",
            "History now: [{'role': 'system', 'content': 'Summary so far: This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.'}, {'role': 'assistant', 'content': 'Loops allow repeating actions. For example, a for loop.'}]\n",
            "Summaries: ['This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.']\n",
            "--------------------------------------------------\n",
            "Added: user: Can you show me an example with numbers?\n",
            "History now: [{'role': 'system', 'content': 'Summary so far: This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.'}, {'role': 'assistant', 'content': 'Loops allow repeating actions. For example, a for loop.'}, {'role': 'user', 'content': 'Can you show me an example with numbers?'}]\n",
            "Summaries: ['This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.']\n",
            "--------------------------------------------------\n",
            "Added: assistant: Sure! for i in range(5): print(i) will print 0â€“4.\n",
            "History now: [{'role': 'system', 'content': \"Summary so far: This conversation is about the user learning Python. Key points so far include:\\n\\n- The user wants to learn Python.\\n- The user has basic knowledge of variables and loops.\\n- An example of a for loop was given using the 'range' function to print numbers from 0 to 4.\"}]\n",
            "Summaries: ['This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.', \"This conversation is about the user learning Python. Key points so far include:\\n\\n- The user wants to learn Python.\\n- The user has basic knowledge of variables and loops.\\n- An example of a for loop was given using the 'range' function to print numbers from 0 to 4.\"]\n",
            "--------------------------------------------------\n",
            "Added: user: Awesome, what about functions?\n",
            "History now: [{'role': 'system', 'content': \"Summary so far: This conversation is about the user learning Python. Key points so far include:\\n\\n- The user wants to learn Python.\\n- The user has basic knowledge of variables and loops.\\n- An example of a for loop was given using the 'range' function to print numbers from 0 to 4.\"}, {'role': 'user', 'content': 'Awesome, what about functions?'}]\n",
            "Summaries: ['This conversation is about learning Python:\\n\\n- The user wants to learn Python.\\n- The assistant confirms Python is easy to learn and asks if the user knows about variables.\\n- The user acknowledges knowing variables to some extent and also has a basic understanding of loops.', \"This conversation is about the user learning Python. Key points so far include:\\n\\n- The user wants to learn Python.\\n- The user has basic knowledge of variables and loops.\\n- An example of a for loop was given using the 'range' function to print numbers from 0 to 4.\"]\n",
            "--------------------------------------------------\n",
            "\n",
            "ðŸ”¹ Truncation by turns (last 3 messages):\n",
            "[{'role': 'system', 'content': \"Summary so far: This conversation is about the user learning Python. Key points so far include:\\n\\n- The user wants to learn Python.\\n- The user has basic knowledge of variables and loops.\\n- An example of a for loop was given using the 'range' function to print numbers from 0 to 4.\"}, {'role': 'user', 'content': 'Awesome, what about functions?'}]\n",
            "\n",
            "ðŸ”¹ Truncation by length (max 100 chars):\n",
            "[{'role': 'user', 'content': 'Awesome, what about functions?'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "# Strict JSON schema\n",
        "schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"required\": [\"name\", \"email\", \"phone\", \"location\", \"age\"],\n",
        "    \"additionalProperties\": False,\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\", \"minLength\": 1},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "        \"phone\": {\"type\": \"string\", \"pattern\": \"^[0-9()+\\\\-\\\\s]{7,20}$\"},\n",
        "        \"location\": {\"type\": \"string\", \"minLength\": 1},\n",
        "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 120}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define the model to be used\n",
        "MODEL = \"llama-3.1-8b-instant\"\n",
        "\n",
        "def extract_structured_data_from_chat(chat_text: str, client=client, model=MODEL, max_retries=2):\n",
        "    schema_str = json.dumps(schema, indent=2, ensure_ascii=False)\n",
        "    system_instructions = (\n",
        "        \"You are an extractor. Given a chat message, produce a single JSON object EXACTLY matching the provided JSON Schema.\\n\"\n",
        "        \"Output ONLY the JSON object and nothing else. If a field cannot be found, set a reasonable default: empty string for strings and -1 for age (but ensure types).\\n\"\n",
        "    )\n",
        "    prompt = (\n",
        "        f\"{system_instructions}\\nJSON Schema:\\n{schema_str}\\n\\nChat message:\\n{chat_text}\\n\\nReturn the JSON object now.\")\n",
        "\n",
        "    raw_response = None\n",
        "    last_exc = None\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]) # Corrected API call\n",
        "            raw_response = getattr(resp, 'output_text', None) or ''\n",
        "            if not raw_response:\n",
        "                try:\n",
        "                    raw_response = resp.choices[0].message.content # Corrected API call\n",
        "                except Exception:\n",
        "                    raw_response = ''\n",
        "            break\n",
        "        except Exception as e:\n",
        "            last_exc = e\n",
        "\n",
        "    if raw_response is None:\n",
        "        raise RuntimeError(f\"Failed to get response from model: {last_exc}\")\n",
        "\n",
        "    raw_text = raw_response.strip()\n",
        "\n",
        "    # Attempt to extract JSON substring\n",
        "    try:\n",
        "        first = raw_text.index('{')\n",
        "        last = raw_text.rindex('}') + 1\n",
        "        json_text = raw_text[first:last]\n",
        "        parsed = json.loads(json_text)\n",
        "    except Exception:\n",
        "        try:\n",
        "            parsed = json.loads(raw_text)\n",
        "        except Exception as e:\n",
        "            return None, raw_text, f\"JSON parse error: {e}\"\n",
        "\n",
        "    # Validate\n",
        "    try:\n",
        "        validate(instance=parsed, schema=schema)\n",
        "        return parsed, raw_text, None\n",
        "    except ValidationError as ve:\n",
        "        return parsed, raw_text, f\"ValidationError: {ve.message} at {list(ve.path)}\"\n",
        "\n",
        "# Demonstration with 3 samples\n",
        "if 'client' in globals():\n",
        "    sample_chats = [\n",
        "        \"Hi, I'm Priya Sharma. You can reach me at priya.sharma@example.com or +91 98765 43210. I live in Bangalore and I'm 27 years old.\",\n",
        "        \"Hello â€” name is John Doe. Email johnny.d@example.org. Phone (415) 555-2671. Location: San Francisco. Age: 34.\",\n",
        "        \"Name: MarÃ­a GonzÃ¡lez\\nEmail: maria.g@correo.mx\\nPhone: +52 1 55 1234 5678\\nLocation: Mexico City\\nAge: 45\"\n",
        "    ]\n",
        "\n",
        "    for i, chat in enumerate(sample_chats, start=1):\n",
        "        parsed, raw, error = extract_structured_data_from_chat(chat)\n",
        "        print('=== Sample', i, '===')\n",
        "        print('Chat:', chat)\n",
        "        print('Raw model output:', raw)\n",
        "        print('Parsed:', json.dumps(parsed, indent=2, ensure_ascii=False) if parsed else None)\n",
        "        print('Error:', error)\n",
        "        print('\\n')\n",
        "else:\n",
        "    print('Client not set. Set GROQ_API_KEY and re-run to demonstrate Task 2.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNIPlhw6hV67",
        "outputId": "318a8547-e7a0-493c-d1ad-d7eeb4f50e10"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Sample 1 ===\n",
            "Chat: Hi, I'm Priya Sharma. You can reach me at priya.sharma@example.com or +91 98765 43210. I live in Bangalore and I'm 27 years old.\n",
            "Raw model output: {\n",
            "  \"name\": \"Priya Sharma\",\n",
            "  \"email\": \"priya.sharma@example.com\",\n",
            "  \"phone\": \"+91 98765 43210\",\n",
            "  \"location\": \"Bangalore\",\n",
            "  \"age\": 27\n",
            "}\n",
            "Parsed: {\n",
            "  \"name\": \"Priya Sharma\",\n",
            "  \"email\": \"priya.sharma@example.com\",\n",
            "  \"phone\": \"+91 98765 43210\",\n",
            "  \"location\": \"Bangalore\",\n",
            "  \"age\": 27\n",
            "}\n",
            "Error: None\n",
            "\n",
            "\n",
            "=== Sample 2 ===\n",
            "Chat: Hello â€” name is John Doe. Email johnny.d@example.org. Phone (415) 555-2671. Location: San Francisco. Age: 34.\n",
            "Raw model output: {\n",
            "  \"name\": \"John Doe\",\n",
            "  \"email\": \"johnny.d@example.org\",\n",
            "  \"phone\": \"(415) 555-2671\",\n",
            "  \"location\": \"San Francisco\",\n",
            "  \"age\": 34\n",
            "}\n",
            "Parsed: {\n",
            "  \"name\": \"John Doe\",\n",
            "  \"email\": \"johnny.d@example.org\",\n",
            "  \"phone\": \"(415) 555-2671\",\n",
            "  \"location\": \"San Francisco\",\n",
            "  \"age\": 34\n",
            "}\n",
            "Error: None\n",
            "\n",
            "\n",
            "=== Sample 3 ===\n",
            "Chat: Name: MarÃ­a GonzÃ¡lez\n",
            "Email: maria.g@correo.mx\n",
            "Phone: +52 1 55 1234 5678\n",
            "Location: Mexico City\n",
            "Age: 45\n",
            "Raw model output: {\n",
            "  \"name\": \"Mar\\u00eda Gonz\\u00e1lez\",\n",
            "  \"email\": \"maria.g@correo.mx\",\n",
            "  \"phone\": \"+52 1 55 1234 5678\",\n",
            "  \"location\": \"Mexico City\",\n",
            "  \"age\": 45\n",
            "}\n",
            "Parsed: {\n",
            "  \"name\": \"MarÃ­a GonzÃ¡lez\",\n",
            "  \"email\": \"maria.g@correo.mx\",\n",
            "  \"phone\": \"+52 1 55 1234 5678\",\n",
            "  \"location\": \"Mexico City\",\n",
            "  \"age\": 45\n",
            "}\n",
            "Error: None\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}